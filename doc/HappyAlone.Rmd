---
title: "Happy Alone"
author: "Gabriel"
date: "9/23/2018"
output: html_document
---

HappyDB is a corpus of 100,000 crowd-sourced happy moments via Amazon's Mechanical Turk. You can read more about it on https://arxiv.org/abs/1801.07746.

Here, we explore this data set and try to answer the question, "What makes people happy?" More precisely, are people able to be happy on their own? How do those people differ from people who feel happy thanks to their surrounding family, friends?

## data


Collection period	3/28/2017 - 6/16/2017
# happy moments	100,922
# distinct users	10,843
# distinct words	38,188
Avg. # happy moments / user	9.31
Avg. # words / happy moment	19.66

### Step 0 - Load all the required libraries

From the packages' descriptions:


```{r load libraries, warning=FALSE, message=FALSE}

library(tidyverse)
library(tidytext)
library(DT)
library(ngram)
library(wordcloud2)

library(scales)

library(gridExtra)

library(shiny) 
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
```

## What defines self-made happiness?

Let's define it as the capacity to make oneself happy by his own making without the interaction of other known humans. We decide here to exclude pets and job relationships, since they can both, to some extent, be categorized as self-made: both relationship generally rely more heavily on one's own decisions.

### Step 1 - Load the processed text data along with demographic information on contributors

We use the processed data for our analysis and combine it with the demographic information available.

```{r load data, warning=FALSE, message=FALSE}
hm_data <- read_csv("../output/processed_moments.csv")

urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data <- read_csv(urlfile)
```

### Combine both the data sets and keep the required columns for analysis

We select a subset of the data that satisfies specific row conditions.

```{r combining data, warning=FALSE, message=FALSE}
hm_data <- hm_data %>%
  inner_join(demo_data, by = "wid") %>%
  select(wid,
         original_hm,
         gender, 
         marital, 
         parenthood,
         reflection_period,
         age, 
         country, 
         ground_truth_category, 
         text,
         others) %>%
  mutate(count = sapply(hm_data$text, wordcount)) %>%
  filter(gender %in% c("m", "f")) %>%
  filter(marital %in% c("single", "married")) %>%
  filter(parenthood %in% c("n", "y")) %>%
  filter(reflection_period %in% c("24h", "3m")) %>%
  mutate(reflection_period = fct_recode(reflection_period, 
                                        months_3 = "3m", hours_24 = "24h"))
```


## boxplot alone vs others


### Create a bag of words using the text data

```{r bag of words, warning=FALSE, message=FALSE}
hm_data_alone <- hm_data[hm_data$others == 0,]
hm_data_others <- hm_data[hm_data$others > 0,]

word_count_alone <- hm_data_alone %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE)

word_count_others <- hm_data_others %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE)

source("wordlists.R")
word_count_others <- word_count_others[! word_count_others$word %in% others,]

```


```{r}
wordcloud2(word_count_alone[1:20,], size = 0.6,
                 rotateRatio = 0)

```

## cddsds


```{r}
wordcloud2(word_count_others[1:20,], size = 0.6,
                 rotateRatio = 0)

```


### Create bigrams using the text data

```{r bigram, warning=FALSE, message=FALSE}
hm_bigrams <- hm_data %>%
  filter(count != 1) %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)

bigram_counts <- hm_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  count(word1, word2, sort = TRUE)

# bigram


```





```{r cars}
# library("topicmodels")
# ap_lda <- LDA(s$cleaned_hm, k = 2, control = list(seed = 1234))
# getwd()
# 
# s$cleaned_hm
```


+ `tidyverse` is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures;
+ `tidytext` allows text mining using 'dplyr', 'ggplot2', and other tidy tools;
+ `DT` provides an R interface to the JavaScript library DataTables;
+ `scales` map data to aesthetics, and provide methods for automatically determining breaks and labels for axes and legends;
+ `wordcloud2` provides an HTML5 interface to wordcloud for data visualization;
+ `gridExtra` contains miscellaneous functions for "grid" graphics;
+ `ngram` is for constructing n-grams (???tokenizing???), as well as generating new text based on the n-gram structure of a given text input (???babbling???);
+ `Shiny` is an R package that makes it easy to build interactive web apps straight from R;

## Sources

Akari Asai, Sara Evensen, Behzad Golshan, Alon Halevy, Vivian Li, Andrei Lopatenko, 
Daniela Stepanov, Yoshihiko Suhara, Wang-Chiew Tan, Yinzhan Xu, 
``HappyDB: A Corpus of 100,000 Crowdsourced Happy Moments'', LREC '18, May 2018. (to appear)
